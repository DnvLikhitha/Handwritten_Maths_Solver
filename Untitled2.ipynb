{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fbbd66-2b39-45fe-a259-f8c8953d339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (5.27.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "Using cached keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.0 markdown-3.7 ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819a0f8-671c-48be-bebc-05fe3b97f3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb13d6f-1a7c-4f87-8545-12ef3829fbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.10-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (24.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chdnv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.10-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc9ee32-3bb9-4d3f-b865-64dba9d0fa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1544 - loss: 2.7290 - val_accuracy: 0.6154 - val_loss: 1.3658\n",
      "Epoch 2/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5238 - loss: 1.5161 - val_accuracy: 0.7801 - val_loss: 0.8102\n",
      "Epoch 3/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6537 - loss: 1.0885 - val_accuracy: 0.8263 - val_loss: 0.6151\n",
      "Epoch 4/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.8586 - val_accuracy: 0.8536 - val_loss: 0.5345\n",
      "Epoch 5/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7616 - loss: 0.7361 - val_accuracy: 0.8754 - val_loss: 0.4312\n",
      "Epoch 6/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7850 - loss: 0.6646 - val_accuracy: 0.8839 - val_loss: 0.3941\n",
      "Epoch 7/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8155 - loss: 0.5833 - val_accuracy: 0.9002 - val_loss: 0.3517\n",
      "Epoch 8/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8369 - loss: 0.5117 - val_accuracy: 0.9027 - val_loss: 0.3257\n",
      "Epoch 9/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8492 - loss: 0.4936 - val_accuracy: 0.9057 - val_loss: 0.3050\n",
      "Epoch 10/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8536 - loss: 0.4439 - val_accuracy: 0.9077 - val_loss: 0.3086\n",
      "Epoch 11/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8637 - loss: 0.4066 - val_accuracy: 0.9067 - val_loss: 0.2998\n",
      "Epoch 12/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8754 - loss: 0.3762 - val_accuracy: 0.9161 - val_loss: 0.2791\n",
      "Epoch 13/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8830 - loss: 0.3609 - val_accuracy: 0.9171 - val_loss: 0.2708\n",
      "Epoch 14/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8927 - loss: 0.3340 - val_accuracy: 0.9261 - val_loss: 0.2565\n",
      "Epoch 15/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8919 - loss: 0.3213 - val_accuracy: 0.9256 - val_loss: 0.2460\n",
      "Epoch 16/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8927 - loss: 0.3115 - val_accuracy: 0.9280 - val_loss: 0.2343\n",
      "Epoch 17/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8968 - loss: 0.3038 - val_accuracy: 0.9256 - val_loss: 0.2479\n",
      "Epoch 18/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9016 - loss: 0.2696 - val_accuracy: 0.9325 - val_loss: 0.2311\n",
      "Epoch 19/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9199 - loss: 0.2354 - val_accuracy: 0.9355 - val_loss: 0.2341\n",
      "Epoch 20/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9197 - loss: 0.2362 - val_accuracy: 0.9295 - val_loss: 0.2428\n",
      "Model saved successfully!\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CD39B0EC00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CD39B0EC00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "Predicted index: 9, Symbol: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load Images from Subfolders\n",
    "dataset_folder = \"C:\\\\Users\\\\chdnv\\\\.cache\\\\kagglehub\\\\datasets\\\\sagyamthapa\\\\handwritten-math-symbols\\\\versions\\\\4\\\\dataset\"\n",
    "symbols = sorted(os.listdir(dataset_folder))  # Ensure consistent label order\n",
    "\n",
    "data, labels = [], []\n",
    "\n",
    "for label, symbol in enumerate(symbols):\n",
    "    folder_path = os.path.join(dataset_folder, symbol)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):  # Skip non-folder files\n",
    "        continue\n",
    "    \n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):  # Skip invalid files\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Skipping invalid image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(data).reshape(len(data), 28, 28, 1) / 255.0  # Normalize to [0,1]\n",
    "y = np.array(labels)\n",
    "\n",
    "# Step 2: Split into Train & Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=len(symbols))\n",
    "y_test = to_categorical(y_test, num_classes=len(symbols))\n",
    "\n",
    "# Step 3: Build CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.6),  # Increased dropout to reduce overfitting\n",
    "    Dense(len(symbols), activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 4: Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train Model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 6: Save Model\n",
    "model.save(\"handwritten_math_solver.keras\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Step 7: Test Prediction on Sample Image\n",
    "def predict_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {img_path}\")\n",
    "        return\n",
    "    \n",
    "    img = cv2.resize(img, (28, 28)) / 255.0\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    print(f\"Predicted index: {predicted_label}, Symbol: {symbols[predicted_label]}\")\n",
    "\n",
    "# Example usage\n",
    "sample_image = \"image2.jpg\"  # Change to your test image path\n",
    "predict_image(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbd5bb6-16b7-4c85-97fa-c46eaff52d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: C:\\Users\\chdnv\\.cache\\kagglehub\\datasets\\sagyamthapa\\handwritten-math-symbols\\versions\\4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "dataset_path = kagglehub.dataset_download(\"sagyamthapa/handwritten-math-symbols\")\n",
    "\n",
    "# Print the dataset path\n",
    "print(\"Dataset Path:\", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d148ecf-55d8-43a7-87d5-98a87c001d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents: ['dataset']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents:\", os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e3433e-621c-423a-b411-15afccdd7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chdnv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.3379 - loss: 2.4450 - val_accuracy: 0.0789 - val_loss: 3.3956\n",
      "Epoch 2/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.6946 - loss: 1.0039 - val_accuracy: 0.6675 - val_loss: 1.0837\n",
      "Epoch 3/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7924 - loss: 0.6754 - val_accuracy: 0.8298 - val_loss: 0.5764\n",
      "Epoch 4/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8290 - loss: 0.5540 - val_accuracy: 0.5752 - val_loss: 3.6904\n",
      "Epoch 5/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8595 - loss: 0.4562 - val_accuracy: 0.8730 - val_loss: 0.4317\n",
      "Epoch 6/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.8771 - loss: 0.4233 - val_accuracy: 0.7911 - val_loss: 0.8701\n",
      "Epoch 7/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.8890 - loss: 0.3608 - val_accuracy: 0.7122 - val_loss: 1.6086\n",
      "Epoch 8/20\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.8966 - loss: 0.3321 - val_accuracy: 0.8556 - val_loss: 0.4928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CD398A1080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CD398A1080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "Predicted index: 9, Symbol: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load Images from Subfolders\n",
    "dataset_folder = \"C:\\\\Users\\\\chdnv\\\\.cache\\\\kagglehub\\\\datasets\\\\sagyamthapa\\\\handwritten-math-symbols\\\\versions\\\\4\\\\dataset\"\n",
    "symbols = sorted(os.listdir(dataset_folder))  # Ensure consistent label order\n",
    "\n",
    "data, labels = [], []\n",
    "\n",
    "for label, symbol in enumerate(symbols):\n",
    "    folder_path = os.path.join(dataset_folder, symbol)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):  # Skip non-folder files\n",
    "        continue\n",
    "    \n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):  # Skip invalid files\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Skipping invalid image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(data).reshape(len(data), 28, 28, 1) / 255.0  # Normalize to [0,1]\n",
    "y = np.array(labels)\n",
    "\n",
    "# Step 2: Split into Train & Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=len(symbols))\n",
    "y_test = to_categorical(y_test, num_classes=len(symbols))\n",
    "\n",
    "# Step 3: Data Augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Step 4: Build CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(len(symbols), activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 5: Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Training with Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(data_gen.flow(X_train, y_train, batch_size=32),\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=20,\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "# Step 7: Save Model\n",
    "model.save(\"handwritten_math_solver.h5\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Step 8: Test Prediction on Sample Image\n",
    "def predict_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {img_path}\")\n",
    "        return\n",
    "    \n",
    "    img = cv2.resize(img, (28, 28)) / 255.0\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    print(f\"Predicted index: {predicted_label}, Symbol: {symbols[predicted_label]}\")\n",
    "\n",
    "# Example usage\n",
    "sample_image = \"image2.jpg\"  # Change to your test image path\n",
    "predict_image(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e31bca-ba74-4213-a76b-ab6e2a502aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b13c8-af34-471e-9833-1b7f6b143005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(math)",
   "language": "python",
   "name": "math"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
